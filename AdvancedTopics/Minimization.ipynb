{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"http://www2.le.ac.uk/liscb1.jpg\">\n",
    "Scipy is the first place to look for general-purpose scientific functionality.  The Scipy library is enormous and varied, so covering all the features is a course unto itself.  Having said that, one of the most commonly used features in scipy is it's fitting routines, which we will now explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local minimization\n",
    "\n",
    "In addition to curve fitting, Scipy provides a number of local (faster,) and global (better,) minimizers.  This allows us to do quite a lot of the parameter finding work we need in science.  If you have a simple problem, especially if you have a decent guess of the final values of the parameters, then local minimization is your tool of choice.  \n",
    "\n",
    "There are lots of local minimizers, and Scipy give us a single interface to get to several of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets repeat the simple Michaelis-Menten example from notebook 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def michaelis_menten(s, km, vmax):\n",
    "    return (vmax*s) / (km + s)\n",
    "\n",
    "substrate_concentrations = np.array([0.01, 0.05, 0.1, 0.5, 1, 2, 3])\n",
    "substrate_concentration_range = np.linspace(0, 3, 1000)\n",
    "\n",
    "km = 0.1\n",
    "vmax = 0.5\n",
    "\n",
    "number_of_concentrations = len(substrate_concentrations)\n",
    "ten_percent_noise = (np.random.normal(loc=0, scale=0.1, size=number_of_concentrations))\n",
    "simulated_data = michaelis_menten(substrate_concentrations, km, vmax) + ten_percent_noise\n",
    "\n",
    "mm_curve = michaelis_menten(substrate_concentration_range, km, vmax)\n",
    "\n",
    "plt.plot(substrate_concentration_range, mm_curve, label='ground truth')\n",
    "plt.scatter(substrate_concentrations, simulated_data, label='simulated data', color='green')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we re-do the curve fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "initial_guess = (1, simulated_data[-1])  # Km and Vmax.  Note the Km is a truly horrible guess, given our data\n",
    "\n",
    "lower_bounds = (0, 0)  # Km, Vmax\n",
    "upper_bounds = (np.inf, np.inf)  # Km, Vmax\n",
    "\n",
    "fitted, covariance = curve_fit(f=michaelis_menten,\n",
    "                               xdata=substrate_concentrations,\n",
    "                               ydata=simulated_data,\n",
    "                               p0=initial_guess,\n",
    "                               bounds=(lower_bounds, upper_bounds)\n",
    "                              )\n",
    "print('Km:', fitted[0])\n",
    "print('Vmax:',fitted[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_curve = michaelis_menten(substrate_concentration_range, fitted[0], fitted[1])\n",
    "\n",
    "plt.plot(substrate_concentration_range, mm_curve, label='ground truth')\n",
    "plt.scatter(substrate_concentrations, simulated_data, label='simulated data', color='green')\n",
    "plt.plot(substrate_concentration_range, calculated_curve, label='fitted')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read the documentation for `curve_fit`, you'll see that it does a non-linear least squares fit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do this, we have to construct a function to minimize.  \n",
    "\n",
    "In this case, we'll minimize the sum-of-squared differences. \n",
    "(This is equivalent to optimizing for the mean.  If we minimized the sum of absolute values, we'd be optimizing for the median.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function(x, substrate_concentrations, observed_initial_rates):\n",
    "    '''\n",
    "    The target function where the first parameter is a sequence of parameters that will be altered to\n",
    "    achieve the minimum return value\n",
    "    \n",
    "    In this example, x will be a 2-tuple with the form (km, vmax)\n",
    "    '''\n",
    "    km=x[0]\n",
    "    vmax=x[1]\n",
    "    \n",
    "    calculated_initial_rates = michaelis_menten(substrate_concentrations, km, vmax)\n",
    "    differences = calculated_initial_rates - observed_initial_rates\n",
    "    error = sum(differences**2)\n",
    "    return error\n",
    "\n",
    "\n",
    "# Sanity check: lets see if the target function gives us a small number when we match the parameters\n",
    "assert target_function((km, vmax),\n",
    "                       substrate_concentrations, \n",
    "                       michaelis_menten(substrate_concentrations, km, vmax)\n",
    "                      ) < 0.01\n",
    "\n",
    "# Sanity check: lets see if the target function give us a big number when we don't match the parameters\n",
    "assert target_function((km*10, vmax*10),\n",
    "                       substrate_concentrations, \n",
    "                       michaelis_menten(substrate_concentrations, km, vmax)\n",
    "                      ) > 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the minimization.  Note that we use the `'SLSQP'` optimizer, as that's the most similar to the one used for curve fitting.  Note also that the bounds are given as tuples of `((min, max), (min, max))`, where they were `((min, min), (max, max))` above.  \n",
    "This function returns a minimization object with a reasonably informative `__str__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(fun=target_function,  # The function to minimize\n",
    "                  x0=initial_guess,\n",
    "                  args=(substrate_concentrations, simulated_data),\n",
    "                  method='SLSQP',\n",
    "                  bounds=((0,None), (0,None))\n",
    "                 )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result is essentially identical to the `curve_fit` above.  This is not surprising as this is essentially how `curve_fit` works.  Note that `curve_fit` is more tolerant to badly chosen starting points than `minimize` is.  Also, notice how much easier `curve_fit` is to use!  \n",
    "\n",
    "So why use `minimize`?  \n",
    "It's much more versatile.  You can provide constraints that force parameters to have equality or inequality relationships.  You can have whatever target function you like - which is how 'robust' fitting methods that are tolerant to large outliers work.  You can control the precision of the fit, trading time for accuracy.  You can try different fitting algorithms to find the one best suited to you problem (or match the one used in a paper you're trying to replicate.)  There are in-fact many reasons to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Fit the median, not the mean\n",
    "Change the target function to calculate the sum of absolute value of the difference between the calculated and measured values.  Plot both fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global minimization\n",
    "If you have the time, let the algorithm work out the best overall place to be.  This makes the initial guess of the parameter values much less important.  Watch out, though, you can wait forever (or at least, longer than the age of the universe,) for these to converge if you give them too big a problem.  \n",
    "\n",
    "We'll look at two algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import basinhopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This acts as a wrapper around your minimizer, essentially trying many different starting points and finding the best.  \n",
    "Note that you have to pass a dictionary of the parameters you'd pass to the `minimize` function above.  Increase niter 10 fold until the answer doesn't change.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinhopping(func=weighted_target_function,  # The function to minimize\n",
    "             x0=initial_guess,               # The initial guess\n",
    "             minimizer_kwargs={'args': (substrate_concentrations, simulated_data),\n",
    "                               'method': 'SLSQP',\n",
    "                               'bounds': ((0,None), (0,None))},\n",
    "             niter=10000\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you have a good idea of the range of values, but no idea where in that range, try differential evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "differential_evolution(func=weighted_target_function,\n",
    "                       args=(substrate_concentrations, simulated_data),\n",
    "                       bounds=((0,10), (0,10))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
